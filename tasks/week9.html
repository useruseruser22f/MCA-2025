<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Week 9: Audio Feature Extraction & Histograms</title>
    <link rel="stylesheet" href="../css/style.css">
</head>

<body>
<main class="content">

    <nav class="tabs">
        <a href="../index.html" class="tab">Week 1</a>
        <a href="week2.html" class="tab">Week 2</a>
        <a href="week3.html" class="tab">Week 3</a>
        <a href="week4.html" class="tab">Week 4</a>
        <a href="week5.html" class="tab">Week 5</a>
        <a href="week7.html" class="tab">Week 7</a>
        <a href="week8.html" class="tab">Week 8</a>
        <a href="week9.html" class="tab active">Week 9</a>
        <a href="week10.html" class="tab">Week 10</a>
    </nav>

    <section class="box">
        <h1>Week 9: Extracting Audio Features & Visualising Histograms</h1>
        <p>
            This week I worked with audio features for three Chopin recordings
            from my dataset theme. I used SonicVisualizer to extract Spectrogram, MFCC and
            Chromagram features and then used Python to compute and visualise histograms of
            these features for basic quantitative comparison.
        </p>
    </section>

    <section class="box">
        <h2>Task 1: Feature Extraction in SonicVisualizer</h2>
        <p>
            I used the same three recordings from my previous labs:
        </p>
        <ul>
            <li><strong>Track 1:</strong> Cantabile in B-flat major, B.84 – Aya Higuchi</li>
            <li><strong>Track 2:</strong> Walzer a-Moll, B.150 – Constantin Stephan</li>
            <li><strong>Track 3:</strong> Nocturne, B.49 in C-sharp minor – Aya Higuchi</li>
        </ul>

        <p>
            For each track, I opened the audio file in SonicVisualizer and created three panes:
        </p>
        <ol>
            <li>A <strong>Spectrogram</strong> (time–frequency energy).</li>
            <li><strong>Mel Frequency Cepstral Coefficients (MFCC)</strong> a compact
                representation of timbre.</li>
            <li>A <strong>Chromagram</strong> pitch class energy over time.</li>
        </ol>

        <p>
            I then took screenshots of the three-pane layouts, and exported the raw feature
            data as CSV files for each track and feature type. My files are organised as:
        </p>

        <ul>
            <li>Spectrogram CSVs:
                <code>data/week9/track1-spectrogram.csv</code>,
                <code>data/week9/track2-spectrogram.csv</code>,
                <code>data/week9/track3-spectrogram.csv</code></li>
            <li>MFCC CSVs:
                <code>data/week9/track1-mfcc.csv</code>,
                <code>data/week9/track2-mfcc.csv</code>,
                <code>data/week9/track3-mfcc.csv</code></li>
            <li>Chromagram CSVs:
                <code>data/week9/track1-chroma.csv</code>,
                <code>data/week9/track2-chroma.csv</code>,
                <code>data/week9/track3-chroma.csv</code></li>
        </ul>


        <h3>Example screenshots from SonicVisualizer</h3>
        <p>
            Below are combined screenshots showing the spectrogram, MFCC and chromagram panes
            for each track:
        </p>

        <h4>Track 1 – Cantabile in B-flat major</h4>
        <img src="../images/week9/track1-sonic.png" alt="Track 1 SonicVisualizer panes"
             style="max-width:100%; height:auto;">

        <h4>Track 2 – Walzer a-Moll, B.150</h4>
        <img src="../images/week9/track2-sonic.png" alt="Track 2 SonicVisualizer panes"
             style="max-width:100%; height:auto;">

        <h4>Track 3 – Nocturne, B.49</h4>
        <img src="../images/week9/track3-sonic.png" alt="Track 3 SonicVisualizer panes"
             style="max-width:100%; height:auto;">
        
    </section>
    <section class="box">
        <h2>Task 2 – Computing and Visualising Histograms</h2>
        <p>
            For Task 2 I moved to Python in a Jupyter notebook and loaded the CSV feature
            files for each track. Using <code>pandas</code> and <code>matplotlib</code>, I
            generated histograms for the spectrogram, MFCC and chroma features.
        </p>

        <h3>Python code used</h3>
<pre><code>import pandas as pd
import matplotlib.pyplot as plt

tracks = {
    "Track 1": {
        "mfcc": "track1-mfcc.csv",
        "chroma": "track1-chroma.csv",
        "spec": "track1-spectrogram.csv"
    },
    "Track 2": {
        "mfcc": "track2-mfcc.csv",
        "chroma": "track2-chroma.csv",
        "spec": "track2-spectrogram.csv"
    },
    "Track 3": {
        "mfcc": "track3-mfcc.csv",
        "chroma": "track3-chroma.csv",
        "spec": "track3-spectrogram.csv"
    }
}

for track_name, files in tracks.items():
    for feature_type, filename in files.items():
        data = pd.read_csv(filename)
        values = data.values.flatten()

        plt.figure(figsize=(8, 4))
        plt.hist(values, bins=50)
        plt.title(f"{track_name} – {feature_type.upper()} histogram")
        plt.xlabel("Value")
        plt.ylabel("Frequency")
        plt.tight_layout()
        plt.show()</code></pre>

        <p>
            For my portfolio I exported the most relevant histograms as images and stored
            them in <code>images/week9/</code> (for example,
            <code>images/week9/track1_mfcc_hist.png</code>, etc.).
        </p>

        <h3>MFCC histogram comparison (Track 1–3)</h3>
        <p>
            Below is an example set of MFCC histograms (one per track):
        </p>

        <img src="../images/week9/track1_mfcc_hist.png" alt="Track 1 MFCC histogram"
             style="max-width:100%; height:auto;">
        <img src="../images/week9/track2_mfcc_hist.png" alt="Track 2 MFCC histogram"
             style="max-width:100%; height:auto;">
        <img src="../images/week9/track3_mfcc_hist.png" alt="Track 3 MFCC histogram"
             style="max-width:100%; height:auto;">

        <h3>Short discussion (MFCC histograms – &lt; 300 words)</h3>
        <p>
            The MFCC histograms show clear, quantitative differences between the three
            recordings, even though all of them are performances of Chopin piano works.
            Track 1 (Cantabile, Aya Higuchi) has MFCC values that are more tightly clustered
            around a narrow range for the lower coefficients, which matches the relatively
            intimate and mellow sound of the recording. Track 2 (Walzer a-Moll, Constantin
            Stephan) shows a broader spread across several MFCC coefficients, suggesting a
            brighter tone and slightly more resonant acoustic environment. Track 3 (Nocturne,
            Aya Higuchi) falls somewhere between the two, with a fairly even distribution that
            reflects its smoother, more legato character and balanced overall timbre.
        </p>
        <p>
            These differences are broadly in line with what I hear when listening to the
            tracks. Track 2 sounds more percussive and forward, which is reflected in the
            wider MFCC distributions, while Track 1 has a softer attack and less high-frequency
            energy. The histograms are not “musical” in themselves, but they do show that
            MFCC features can discriminate between interpretations and recording setups,
            even when the underlying musical material, Chopin piano pieces, is similar.
            This illustrates how MFCCs can be used for tasks such as similarity search,
            clustering, or style classification in larger audio collections.
        </p>
    </section>

</main>
</body>
</html>

